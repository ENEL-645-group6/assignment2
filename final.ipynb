{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, datasets\n",
    "import os\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from torch.optim import AdamW, SGD\n",
    "from torch.utils.data import DataLoader\n",
    "import re\n",
    "import numpy as np\n",
    "from image_and_text_dataset import ImageTextGarbageDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data directories. Modify the path to your local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/rzhang/Desktop/talc_assignment_2\"\n",
    "train_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Train\")\n",
    "val_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Val\")\n",
    "test_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define transformations for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Classifier:\n",
    "1. Image feature extractor: ResNet50\n",
    "2. Text feature extractor: DistilBERT\n",
    "3. Fusion and classification layers\n",
    "4. Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetMultimodalClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Image feature extractor (ResNet50)\n",
    "        resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.image_features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        \n",
    "        # Text feature extractor (DistilBERT)\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.text_drop = nn.Dropout(0.3)\n",
    "        \n",
    "        # Freeze DistilBERT parameters\n",
    "        for param in self.distilbert.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Fusion and classification layers\n",
    "        self.image_fc = nn.Linear(2048, 512)  # ResNet50 features\n",
    "        self.text_fc = nn.Linear(768, 512)    # DistilBERT features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 512),  # 512 + 512 = 1024\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        # Process images\n",
    "        img_features = self.image_features(images)\n",
    "        img_features = img_features.squeeze(-1).squeeze(-1)\n",
    "        img_features = self.image_fc(img_features)\n",
    "\n",
    "        # Process text\n",
    "        text_output = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        text_features = self.text_drop(text_output[:,0])\n",
    "        text_features = self.text_fc(text_features)\n",
    "\n",
    "        # Combine features\n",
    "        combined_features = torch.cat((img_features, text_features), dim=1)\n",
    "        output = self.classifier(combined_features)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Training Function:\n",
    "1. Best accuracy\n",
    "2. For each epoch\n",
    "3. For each phase\n",
    "4. Forward pass\n",
    "5. Backward pass\n",
    "6. Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10, device=None):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for batch in dataloaders[phase]:\n",
    "                images = batch['image'].to(device)\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(images, input_ids, attention_mask)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "            \n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), \"final_resnet_adamW_model.pth\")\n",
    "\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Training:\n",
    "1. Set device\n",
    "2. Create datasets\n",
    "3. Create dataloaders\n",
    "4. Create model\n",
    "5. Define loss function\n",
    "6. Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Epoch 1/8\n",
      "train Loss: 0.9079 Acc: 0.6333\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = (\n",
    "        torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "        else torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "        else torch.device(\"cpu\")\n",
    "    )\n",
    "print(f\"Using device: {device}\")\n",
    "    \n",
    "# Create datasets\n",
    "max_len = 24\n",
    "data_splits = {\n",
    "        \"train\": ImageTextGarbageDataset(train_dir, transform=transform[\"train\"], max_len=max_len),\n",
    "        \"val\": ImageTextGarbageDataset(val_dir, transform=transform[\"val\"], max_len=max_len),\n",
    "        \"test\": ImageTextGarbageDataset(test_dir, transform=transform[\"test\"], max_len=max_len),\n",
    "    }\n",
    "\n",
    "# Create dataloaders\n",
    "dataloaders = {\n",
    "    \"train\": DataLoader(data_splits[\"train\"], batch_size=32, shuffle=True, num_workers=2),\n",
    "    \"val\": DataLoader(data_splits[\"val\"], batch_size=32, shuffle=False, num_workers=2),\n",
    "    \"test\": DataLoader(data_splits[\"test\"], batch_size=32, shuffle=False, num_workers=2)\n",
    "}\n",
    "    \n",
    "# Create model\n",
    "model = ResNetMultimodalClassifier(num_classes=4).to(device)\n",
    "    \n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "#AdamW (Adam with weight decay)\n",
    "optimizer = AdamW(model.parameters(), \n",
    "                     lr=2e-5,\n",
    "                     weight_decay=0.01)  # L2 regularization\n",
    "    \n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, dataloaders, criterion, optimizer, num_epochs=8, device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define data directory\n",
    "data_dir = \"/Users/rzhang/Desktop/talc_assignment_2\"\n",
    "test_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Test\")\n",
    "\n",
    "# Get class names from the test directory and filter out hidden files\n",
    "class_names = sorted([f for f in os.listdir(test_dir) \n",
    "                     if not f.startswith('.') and os.path.isdir(os.path.join(test_dir, f))])\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "    else torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create and load model\n",
    "model = ResNetMultimodalClassifier(num_classes=4).to(device)\n",
    "model.load_state_dict(torch.load(\"final_resnet_adamW_model.pth\", weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "# Create test dataset and dataloader\n",
    "test_dataset = ImageTextGarbageDataset(test_dir, transform=transform[\"test\"])\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images = batch['image'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(images, input_ids, attention_mask)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test set: {accuracy:.2f}%')\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot confusion matrix with class names\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, \n",
    "            yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Calculate and display per-class accuracy with class names\n",
    "per_class_accuracy = cm.diagonal() / cm.sum(axis=1) * 100\n",
    "for i, (name, acc) in enumerate(zip(class_names, per_class_accuracy)):\n",
    "    print(f'Accuracy for {name}: {acc:.2f}%') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
